{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import jsonschema\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_file(filepath):\n",
    "    \"\"\"\n",
    "    This function determines the file data type and appropriately\n",
    "    imports the file as a pandas object\n",
    "    It also partially accounts for the bug where date\n",
    "    parsing in pandas cannot be set to False for pd.read_excel()\n",
    "\n",
    "    :param filepath: path to the excel file\n",
    "    :type filepath: str\n",
    "    :returns:  data_frame, a pandas dataframe without date\n",
    "    \"\"\"\n",
    "    if filepath.endswith(('.xls', '.xlsx')):\n",
    "        # read in dataframe from xls/xlsx\n",
    "        dataframe = pd.read_excel(filepath)\n",
    "\n",
    "        # if there are no datetimes series found, return  the\n",
    "        if dataframe.select_dtypes('datetime64').empty:\n",
    "            return dataframe\n",
    "        # otherwise, convert to string and replace any NaT with NaN\n",
    "        else:\n",
    "            print('fixing datetime')\n",
    "            # select the offending columns\n",
    "            dtcolumns = dataframe.select_dtypes('datetime64').columns\n",
    "            # loop over the columns\n",
    "            for column in dtcolumns:\n",
    "                # convert to string type\n",
    "                dataframe[column] = dataframe[column].astype('str')\n",
    "                # handle NaTs\n",
    "                dataframe[column] = dataframe[column].replace('NaT', np.nan)\n",
    "            return dataframe\n",
    "    elif filepath.endswith('.csv'):\n",
    "        dataframe = pd.read_csv(filepath)\n",
    "        return dataframe\n",
    "    else:\n",
    "        print('File type is not supported')\n",
    "\n",
    "\n",
    "def convert_value(value):\n",
    "    \"\"\"\n",
    "    converts all objects to strings and handles trailing .0 on ints\n",
    "    since pandas likes to spit out floats\n",
    "    \"\"\"\n",
    "    if type(value) == str:\n",
    "        return value\n",
    "    else:\n",
    "        # convert to string\n",
    "        value = str(value)\n",
    "        # clip trailing .0\n",
    "        value = re.sub('\\.0+$', '',value)\n",
    "        return value\n",
    "\n",
    "\n",
    "def export_to_dict(dataframe):\n",
    "    \"\"\"\n",
    "    This function exports a pandas dataframe object\n",
    "    to a dictionary\n",
    "\n",
    "    :param dataframe: a pandas DataFrame object\n",
    "    :type filepath: DataFrame\n",
    "    :returns:  output_dic (dict) - the output object to be converted to json\n",
    "\n",
    "    \"\"\"\n",
    "    # for now, assume subject is the first column\n",
    "    subject_column = dataframe.columns[0]\n",
    "    # get the count of the non-null subjects\n",
    "    subject_count = dataframe[subject_column].count()\n",
    "    # check that the above returned a value\n",
    "    if type(subject_count) != np.int64:\n",
    "        print(\"subject_count is not a valid integer. Dictionary not created.\")\n",
    "    # if there's only one subject, account for possibility of list columnns\n",
    "    elif subject_count == 1:\n",
    "        print(\"Processing single subject...\")\n",
    "        output_dict = {}\n",
    "        for column in dataframe:\n",
    "            if dataframe[column].count() > 1:\n",
    "                output_dict[column] = dataframe[column].dropna().tolist()\n",
    "            else:\n",
    "                value = dataframe[column][0]\n",
    "                #value = convert_value(value)\n",
    "                output_dict[column] = value\n",
    "        # output_json = json.dumps(output_dict)\n",
    "        return output_dict\n",
    "    elif subject_count < 1:\n",
    "        print(\"No subjects in DataFrame. Dictionary not created.\")\n",
    "    else:\n",
    "        print(\"Processing multiple subjects...\")\n",
    "        output_dict = {}\n",
    "        dataframe = dataframe.astype(\"str\")\n",
    "        for index, row in dataframe.iterrows():\n",
    "            key = row[subject_column]\n",
    "            value = row.to_dict()\n",
    "            output_dict[key] = value\n",
    "        # output_json = json.dumps(output_dict)\n",
    "        return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixing datetime\n",
      "Processing single subject...\n",
      "Processing single subject...\n"
     ]
    }
   ],
   "source": [
    "xls_filepath = \"input.metadata.xlsx\"\n",
    "csv_filepath = \"input.metadata.csv\"\n",
    "xls_dataframe = import_file(xls_filepath)\n",
    "csv_dataframe = import_file(csv_filepath)\n",
    "xls_dict = export_to_dict(xls_dataframe)\n",
    "csv_dict = export_to_dict(csv_dataframe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_filepath = \"mr.metadata.template.json\"\n",
    "\n",
    "with open(template_filepath) as template_data:\n",
    "    template_json = json.load(template_data)\n",
    "JSON_template = {}\n",
    "JSON_template['type'] = 'object'\n",
    "JSON_template['properties'] = template_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonschema.validate(xls_dict,template_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xls_dict['StudyInstanceUID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality\n",
      "MagneticFieldStrength\n",
      "SeriesInstanceUID\n",
      "StudyInstanceUID\n",
      "StudyID\n",
      "PatientID\n",
      "BodyPartExamined\n",
      "MRAcquisitionType\n",
      "SeriesDescription\n",
      "ScanningSequence\n",
      "SliceThickness\n",
      "EchoTime\n",
      "RepetitionTime\n",
      "ClinicalTrialTimePointID\n",
      "ClinicalTrialTimePointDescription\n",
      "PixelSpacing\n",
      "InversionTime\n"
     ]
    }
   ],
   "source": [
    "required_array = []\n",
    "for key in JSON_template['properties']:\n",
    "    try:\n",
    "        if JSON_template['properties'][key]['required'] is True:\n",
    "            print(key)\n",
    "            required_array.append(key)\n",
    "            JSON_template['properties'][key].pop('required', None)\n",
    "    except KeyError:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_template['required'] = required_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'fail_fast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-720c5fea4227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjsonschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJSON_template\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfail_fast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/jsonschema/validators.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(instance, schema, cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidator_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m     \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'fail_fast'"
     ]
    }
   ],
   "source": [
    "jsonschema.validate(csv_dict,JSON_template,fail_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Draft3Validator',\n",
       " 'Draft4Validator',\n",
       " 'ErrorTree',\n",
       " 'FormatChecker',\n",
       " 'FormatError',\n",
       " 'RefResolutionError',\n",
       " 'RefResolver',\n",
       " 'SchemaError',\n",
       " 'ValidationError',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_format',\n",
       " '_utils',\n",
       " '_validators',\n",
       " '_version',\n",
       " 'compat',\n",
       " 'draft3_format_checker',\n",
       " 'draft4_format_checker',\n",
       " 'exceptions',\n",
       " 'validate',\n",
       " 'validators']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(jsonschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'string',\n",
       " 'pattern': '/MR/',\n",
       " 'description': \"Modality must match 'MR'\"}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_template['properties']['Modality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'jsonschema' has no attribute 'Draft7Validator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-1429c90d7dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDraft7Validator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSON_template\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'jsonschema' has no attribute 'Draft7Validator'"
     ]
    }
   ],
   "source": [
    "\n",
    "v = jsonschema.Draft7Validator(JSON_template)\n",
    "errors = sorted(v.iter_errors(csv_dict), key=lambda e: e.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
